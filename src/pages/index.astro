---
import CompaSwag from '../components/CompaSwag.astro'
import Shell from '../layouts/Shell.astro'
---

<Shell title="Home">
	<div class="container mx-auto">
		<div class="text-secondary mx-auto max-w-[20rem] text-center font-medium">
			Private AI Chat, Powered Locally
		</div>

		<div class="py-16 flex justify-center">
			<div class="w-3/4 max-w-4xl">
				<CompaSwag />
			</div>
		</div>

		<div class="mx-auto text-center font-medium md:max-w-[35rem]">
			<span class="text-secondary">About:</span>
			<h1 class="inline">
				Offeline is a powerful, privacy-first AI chat application with both browser and desktop support. Run open-source LLMs locally on your hardware with multiple backend options. Your data never leaves your machine.
			</h1>
		</div>

		<div class="mt-10 flex justify-center">
			<div class="w-full max-w-4xl rounded-lg overflow-hidden shadow-lg">
				<video
					autoplay
					loop
					muted
					playsinline
					class="w-full h-auto"
				>
					<source src="/demo.mp4" type="video/mp4" />
					Your browser does not support the video tag.
				</video>
			</div>
		</div>

		<section class="mt-14">
			<h2 class="mb-8 text-center text-3xl font-bold md:text-5xl">
				Features
			</h2>

			<div class="grid grid-cols-1 gap-10 md:grid-cols-2 lg:grid-cols-3">
				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Complete Privacy</h3>

					<p>
						All AI models run locally on your hardware. No data is sent to external servers.
					</p>

					<p class="text-secondary mt-2">
						Process everything on your machine with complete privacy.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Multi-Platform</h3>

					<p>
						Use via browser (web app) or native desktop application with Electron.
					</p>

					<p class="text-secondary mt-2">
						Seamless experience across all your devices.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Offline-Capable</h3>

					<p>
						Download models once, use them offline indefinitely.
					</p>

					<p class="text-secondary mt-2">
						WebGPU mode enables true offline operation.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Rich Chat Interface</h3>

					<p>
						Clean, intuitive conversation interface with real-time streaming responses.
					</p>

					<p class="text-secondary mt-2">
						Perfect for any conversation and interaction.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">File Embeddings</h3>

					<p>
						Load and ask questions about documents (PDF, MD, DOCX, TXT, CSV, RTF).
					</p>

					<p class="text-secondary mt-2">
						Fully local document processing and analysis.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Voice Support</h3>

					<p>
						Interact with the AI using voice messages.
					</p>

					<p class="text-secondary mt-2">
						Communicate naturally and hands-free.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Regenerate Responses</h3>

					<p>
						Quickly regenerate AI responses without retyping prompts.
					</p>

					<p class="text-secondary mt-2">
						Refine and iterate easily on your conversations.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Chat History</h3>

					<p>
						Persistent, organized conversation history across sessions.
					</p>

					<p class="text-secondary mt-2">
						Never lose your important chats and conversations.
					</p>
				</div>

				<div class="col-span-1">
					<h3 class="mb-2 text-xl font-bold">Custom Memory</h3>

					<p>
						Add custom system prompts and memory to personalize AI behavior.
					</p>

					<p class="text-secondary mt-2">
						Make the AI truly yours with custom instructions.
					</p>
				</div>
			</div>
		</section>

		<div class="py-16 flex flex-col items-center justify-center">
			<h3 class="text-2xl font-bold mb-6 text-center">Ready to experience private AI?</h3>
			<a href="https://github.com/iBz-04/offeline" class="inline-block bg-zinc-900 hover:bg-black dark:bg-white dark:hover:bg-zinc-200 dark:text-zinc-900 text-white font-medium py-3 px-12 rounded-full transition-all hover:shadow-md text-lg">Get Offeline</a>
		</div>

		<section class="mt-20 py-16 border border-zinc-200 dark:border-neutral-700 rounded-xl">
			<h2 class="mb-12 text-center text-5xl font-bold">
				ðŸ”§ Supported Backends
			</h2>

			<div class="container mx-auto max-w-5xl">
				<div class="grid grid-cols-1 md:grid-cols-3 gap-8">
					<div class="col-span-1 p-8 bg-white dark:bg-neutral-800 rounded-lg border border-zinc-100 dark:border-neutral-700 shadow-sm transition-all hover:shadow-md">
						<div class="flex items-center justify-center h-16 w-16 rounded-full bg-zinc-100 dark:bg-neutral-700 mx-auto mb-6">
							<svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 text-zinc-700 dark:text-zinc-300" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<circle cx="12" cy="12" r="10"></circle>
								<path d="M12 6v6l4 2"></path>
							</svg>
						</div>
						<h3 class="mb-4 text-2xl font-bold text-center">WebGPU</h3>
						<p class="text-center">
							Run models directly in your browser using GPU acceleration. Native browser-based inference with no installation needed.
						</p>

						<p class="text-secondary mt-4 text-center text-sm">
							Browser â€¢ GPU â€¢ No setup required
						</p>
					</div>

					<div class="col-span-1 p-8 bg-white dark:bg-neutral-800 rounded-lg border border-zinc-100 dark:border-neutral-700 shadow-sm transition-all hover:shadow-md">
						<div class="flex items-center justify-center h-16 w-16 rounded-full bg-zinc-100 dark:bg-neutral-700 mx-auto mb-6">
							<svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 text-zinc-700 dark:text-zinc-300" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
								<line x1="9" y1="9" x2="15" y2="9"></line>
								<line x1="9" y1="15" x2="15" y2="15"></line>
							</svg>
						</div>
						<h3 class="mb-4 text-2xl font-bold text-center">Ollama</h3>
						<p class="text-center">
							Easy model management with Ollama backend. Manage and run models with simple commands across Windows, Mac, and Linux.
						</p>

						<p class="text-secondary mt-4 text-center text-sm">
							Desktop â€¢ CPU/GPU â€¢ Easy management
						</p>
					</div>

					<div class="col-span-1 p-8 bg-white dark:bg-neutral-800 rounded-lg border border-zinc-100 dark:border-neutral-700 shadow-sm transition-all hover:shadow-md">
						<div class="flex items-center justify-center h-16 w-16 rounded-full bg-zinc-100 dark:bg-neutral-700 mx-auto mb-6">
							<svg xmlns="http://www.w3.org/2000/svg" class="h-8 w-8 text-zinc-700 dark:text-zinc-300" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path>
								<polyline points="13 2 13 9 20 9"></polyline>
							</svg>
						</div>
						<h3 class="mb-4 text-2xl font-bold text-center">llama.cpp</h3>
						<p class="text-center">
							Direct integration with optimized performance. CPU/GPU optimized inference on desktop with direct integration.
						</p>

						<p class="text-secondary mt-4 text-center text-sm">
							Desktop â€¢ CPU/GPU â€¢ Optimized
						</p>
					</div>
				</div>
			</div>
		</section>
	</div>
</Shell>
